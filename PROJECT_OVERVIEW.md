# ğŸš— PROJECT ADAR V3.0 â€” Complete Technical Overview

> **Advanced Driver Attention & Response System**
> Built for the **OpenAI Buildathon Grand Finale 2026**
> Version: 3.0.2 | Python 3.10.11 | Windows 11

---

## ğŸ“‹ Table of Contents

1. [What Is ADAR?](#1-what-is-adar)
2. [Project Structure](#2-project-structure)
3. [System Architecture](#3-system-architecture)
4. [Technology Stack](#4-technology-stack)
5. [Core Modules (Detailed)](#5-core-modules-detailed)
6. [AI Detection Pipeline](#6-ai-detection-pipeline)
7. [Alert System â€” 2-Path Architecture](#7-alert-system--2-path-architecture)
8. [Dashboard & Frontend](#8-dashboard--frontend)
9. [Database & Logging](#9-database--logging)
10. [Configuration & Thresholds](#10-configuration--thresholds)
11. [Threading Model](#11-threading-model)
12. [Key Features Summary](#12-key-features-summary)
13. [How To Run](#13-how-to-run)

---

## 1. What Is ADAR?

ADAR (Advanced Driver Attention & Response) is a **real-time AI-powered driver safety monitoring system** that uses computer vision and frontier AI models to detect dangerous driving behaviors and alert the driver with spoken voice warnings.

The system watches the driver through a webcam and detects:
- **Drowsiness** (eyes closing, micro-sleep)
- **Yawning** (mouth opening)
- **Distraction** (phone use, drinking, objects in hand)
- **Head pose deviation** (looking away from road)
- **Hand-to-face behaviors** (phone near ear, hand on head)

When danger is detected, the system:
1. Analyzes the situation using **OpenAI GPT-5.2 Vision** (frontier model)
2. Generates a **spoken voice alert** using OpenAI TTS
3. Plays the warning through speakers in real-time
4. Logs every incident to an SQLite database
5. Shows everything on a live **Iron Man / JARVIS-themed web dashboard**

The AI assistant is named **J.A.R.V.I.S.** (inspired by Iron Man's AI), and all the UI/UX follows that design language.

---

## 2. Project Structure

```
E:\ADAR V3.0\
â”‚
â”œâ”€â”€ main.py                    # Entry point â€” starts Flask + SocketIO server
â”œâ”€â”€ config.py                  # Central configuration (all thresholds, API keys, model settings)
â”œâ”€â”€ requirements.txt           # Python dependencies
â”œâ”€â”€ face_landmarker.task       # MediaPipe Face Landmarker model file (pre-trained)
â”œâ”€â”€ yolov8n.pt                 # YOLOv8 Nano model weights (object detection)
â”œâ”€â”€ pyrightconfig.json         # Type checker config
â”œâ”€â”€ adar_logs.db               # SQLite database (auto-created at runtime)
â”‚
â”œâ”€â”€ app/                       # Flask application package
â”‚   â”œâ”€â”€ __init__.py            # Flask app factory + SocketIO init
â”‚   â”œâ”€â”€ ai_core.py             # AI detection engine (1559 lines) â€” MediaPipe + YOLO + all detection logic
â”‚   â”œâ”€â”€ camera.py              # Lock-free threaded camera capture
â”‚   â”œâ”€â”€ database.py            # SQLAlchemy models + incident logging
â”‚   â”œâ”€â”€ jarvis.py              # GPT-5.2 Vision + TTS alert pipeline
â”‚   â””â”€â”€ routes.py              # Flask routes, engine controller, background threads
â”‚
â”œâ”€â”€ templates/
â”‚   â””â”€â”€ dashboard.html         # JARVIS-themed web dashboard (single page)
â”‚
â”œâ”€â”€ static/
â”‚   â”œâ”€â”€ css/
â”‚   â”‚   â””â”€â”€ style.css          # Full JARVIS/Iron Man themed CSS
â”‚   â””â”€â”€ js/
â”‚       â””â”€â”€ dashboard.js       # SocketIO client, Chart.js graphs, real-time UI updates
â”‚
â””â”€â”€ .venv/                     # Python virtual environment
```

---

## 3. System Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   CAMERA     â”‚â”€â”€â”€â”€â–¶â”‚   AI CORE    â”‚â”€â”€â”€â”€â–¶â”‚   TELEMETRY     â”‚
â”‚  (camera.py) â”‚     â”‚ (ai_core.py) â”‚     â”‚  via SocketIO   â”‚
â”‚  Lock-free   â”‚     â”‚  MediaPipe   â”‚     â”‚  to Dashboard   â”‚
â”‚  30fps       â”‚     â”‚  + YOLOv8    â”‚     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
                           â”‚
                    â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚  ALERT LOGIC â”‚
                    â”‚ (routes.py)  â”‚
                    â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
                           â”‚
              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
              â–¼                         â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚  PATH A: LOCAL   â”‚      â”‚  PATH B: GPT-5.2  â”‚
    â”‚  Drowsy 4s+      â”‚      â”‚  Vision Analysis   â”‚
    â”‚  Instant alert   â”‚      â”‚  + JSON response   â”‚
    â”‚  (no API call)   â”‚      â”‚  + TTS audio       â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚                        â”‚
             â–¼                        â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚  OpenAI TTS      â”‚      â”‚  OpenAI TTS       â”‚
    â”‚  â†’ pygame audio  â”‚      â”‚  â†’ pygame audio   â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚                        â”‚
             â–¼                        â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚        SQLite Database           â”‚
    â”‚     + Dashboard SocketIO         â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Thread Model

| Thread | Name | Purpose |
|--------|------|---------|
| **Main** | Flask/SocketIO | Serves web dashboard, handles HTTP & WebSocket |
| **Camera** | Camera Thread | Captures frames at 30fps, lock-free atomic swap |
| **Thread A** | Processing Loop | Reads camera â†’ AI detection â†’ emit telemetry â†’ trigger alerts |
| **Thread C** | Spatial Scan | Every 5s, sends a frame to GPT-5.2 for room/environment analysis |
| **Alert Threads** | Jarvis Workers | Spawned on-demand for GPT-5.2 calls + TTS + audio playback |

---

## 4. Technology Stack

### Backend (Python 3.10.11)
| Component | Technology | Purpose |
|-----------|-----------|---------|
| Web Framework | **Flask 3.1+** | Serves dashboard, API routes |
| Real-time | **Flask-SocketIO 5.5+** | WebSocket telemetry streaming |
| Face Detection | **MediaPipe Face Landmarker** | 478 facial landmarks, eye/mouth tracking |
| Object Detection | **YOLOv8 Nano** (Ultralytics) | Detects phone, bottle, cup, etc. |
| Hand Detection | **MediaPipe Hands** | Detects hand position relative to face |
| AI Vision | **OpenAI GPT-5.2** (Vision) | Analyzes driver frames, returns JSON danger assessment |
| Text-to-Speech | **OpenAI TTS-1** (voice: onyx) | Generates spoken voice warnings |
| Audio Playback | **pygame-ce 2.5+** | Plays TTS audio through speakers |
| Computer Vision | **OpenCV 4.11+** | Frame capture, encoding, image processing |
| Database | **SQLAlchemy 2.0+** + SQLite | Logs every incident with full telemetry |
| Math | **NumPy, SciPy** | EAR/MAR calculations, head pose estimation |

### Frontend
| Component | Technology | Purpose |
|-----------|-----------|---------|
| Dashboard | **HTML5 / CSS3 / JavaScript** | Single-page JARVIS-themed command center |
| Real-time Updates | **Socket.IO 4.7** | Live telemetry from backend |
| Charts | **Chart.js 4.4** | EAR/MAR timeline graph |
| Fonts | **Orbitron, Rajdhani, Share Tech Mono** | Iron Man / sci-fi aesthetic |

### Hardware Requirements
| Component | Spec |
|-----------|------|
| GPU | NVIDIA RTX 2050 (4GB VRAM) â€” used by YOLO |
| CPU | AMD Ryzen 5 5600H |
| Camera | Any USB webcam (configured for 640Ã—480 @ 30fps) |
| OS | Windows 11 |

---

## 5. Core Modules (Detailed)

### 5.1 `main.py` â€” Entry Point
- Prints the ADAR ASCII art banner
- Shows system status (dashboard URL, camera source, Jarvis online/offline)
- Creates the Flask app via `create_app()`
- Runs SocketIO server on `0.0.0.0:5000`
- Handles Ctrl+C graceful shutdown

### 5.2 `config.py` â€” Central Configuration
All tunable parameters live here. Key settings:

| Setting | Value | Purpose |
|---------|-------|---------|
| `OPENAI_MODEL` | `"gpt-5.2"` | Frontier model â€” fast, non-reasoning, vision-capable |
| `GPT_TIMEOUT` | `3.0` seconds | If GPT-5.2 exceeds this, local fallback fires |
| `EAR_THRESHOLD` | `0.25` | Eye Aspect Ratio below this = eyes closing |
| `EAR_CONSEC_FRAMES` | `15` | Frames below threshold to confirm drowsiness |
| `MAR_THRESHOLD` | `0.70` | Mouth Aspect Ratio above this = yawning |
| `HEAD_YAW_THRESHOLD` | `25Â°` | Looking sideways beyond this = looking away |
| `HEAD_PITCH_THRESHOLD` | `20Â°` | Looking up/down beyond this = looking away |
| `JARVIS_COOLDOWN` | `5` seconds | Minimum time between consecutive alerts |
| `DROWSY_ALERT_DURATION` | `4.0` seconds | Drowsy timer must reach this to trigger DANGER |
| `DANGER_FRAME_THRESHOLD` | `5` | Consecutive DANGER frames before GPT-5.2 alert |
| `SPATIAL_SCAN_INTERVAL` | `5.0` seconds | How often Thread C scans the room |
| `YOLO_CONFIDENCE` | `0.45` | YOLO detection threshold |
| `OPENAI_TTS_VOICE` | `"onyx"` | Deep male voice for JARVIS |

Safety status levels: `SAFE`, `WARNING`, `DANGER`

### 5.3 `app/camera.py` â€” Lock-Free Threaded Camera
- Opens webcam via OpenCV (DirectShow backend on Windows for lowest latency)
- Runs a dedicated background thread that continuously captures frames
- Uses **atomic reference swap** (no threading.Lock) for zero-latency frame access
- Configures: 640Ã—480, 30fps, MJPG codec, manual exposure, buffer size 1
- Auto-reconnects if camera connection is lost
- Flips frame horizontally for natural mirror view
- Tracks real-time FPS

### 5.4 `app/ai_core.py` â€” AI Detection Engine (1559 lines)
This is the heart of the system. It contains:

#### Face Detection (MediaPipe Face Landmarker)
- Extracts 478 facial landmarks per frame
- Calculates **EAR** (Eye Aspect Ratio) â€” measures eye openness
- Calculates **MAR** (Mouth Aspect Ratio) â€” measures mouth openness
- Estimates **head pose** (yaw + pitch) using solvePnP with 3D model points
- Detects **blinks** by tracking EAR transitions (falling edge detection)
- Calculates **blink rate** (blinks per minute) over a rolling 60-second window

#### Drowsiness Detection (Multi-Factor, ~95% Accuracy)
- **Primary**: EAR below 0.25 for 15+ consecutive frames
- **Secondary**: Very low EAR (< 0.25 Ã— 0.85) for 5+ frames
- **Tertiary**: Base drowsy + abnormal blink rate (< 5 or > 30 blinks/min)
- **Drowsy timer**: Tracks how long drowsiness has been sustained
  - 10-frame grace period prevents brief EAR fluctuations from resetting the timer
  - Timer reaching 4 seconds triggers DANGER state + instant local alert

#### Yawning Detection
- **Primary**: MAR above 0.70 for 8+ consecutive frames
- **Secondary**: Extreme MAR (> 0.70 Ã— 1.2) for 3+ frames

#### Looking Away Detection (with hysteresis)
- Yaw > 25Â° or Pitch > 20Â° triggers "looking away"
- Uses frame counter with asymmetric increase/decrease to prevent false positives
- Must be looking away for 3+ frames to confirm

#### Object Detection (YOLOv8 Nano)
- Runs every 10th frame (to save GPU resources)
- Detects: cell phone, bottle, cup, scissors, knife, laptop, backpack, etc.
- Objects in `_DISTRACTION_OBJECTS` set trigger distraction alerts

#### Hand Detection (MediaPipe Hands)
- Detects up to 2 hands per frame
- Calculates hand position relative to face
- Detects: hand near face, hand on head, phone near ear

#### Advanced Behavior Analysis
- **Phone near ear**: Hand holding phone close to ear region
- **Looking down**: Pitch angle below -20Â° sustained
- **Drinking**: Bottle/cup detected near face region
- **Tiredness level**: Composite 0-100 score combining EAR history, blink rate, yawn frequency
- **Affective state**: ALERT / TIRED / DROWSY / DISTRACTED

#### Attention Score (0-100 Composite)
Weighted combination of:
- EAR (30%) â€” eye openness
- Blink rate (15%) â€” abnormal = lower score
- MAR (15%) â€” yawning = lower score
- Head pose (20%) â€” looking away = lower score
- Distraction (20%) â€” objects/behaviors = lower score
- Temporal smoothing (70% current + 30% previous) for stability

#### Safety Status (3 Levels)
- **DANGER**: 2+ danger factors, attention < 20, critical drowsy, extreme distraction, or dangerous behavior (phone/drinking)
- **WARNING**: 1 danger factor, attention < 45, or severe looking away
- **SAFE**: No danger factors detected

#### JARVIS HUD Overlay (Built-in but NOT shown on camera feed)
The ai_core contains a full Iron Man-style HUD overlay system with 12 visual layers including:
- Helmet visor vignette
- 3D depth-shaded face mesh
- Rotating targeting reticle
- Iron Man object detection boxes
- System integrity bars
- Mini radar, process monitor
- Corner brackets with neon glow

> **Note**: The HUD overlay is NOT drawn on the live camera feed (kept clean by design). It exists in the code and can be enabled if desired.

### 5.5 `app/jarvis.py` â€” GPT-5.2 Vision + TTS Alert Pipeline
The voice alert assistant. Key features:

#### Two Alert Methods

**1. `trigger_alert(frame, telemetry)` â€” GPT-5.2 Path**
Used for: EAR below threshold, danger frames, distraction
Pipeline:
1. Encode camera frame to base64 JPEG
2. Build context prompt with sensor readings (EAR, MAR, Yaw, Pitch, Attention, BlinkRate)
3. Send to GPT-5.2 Vision with image + ask for JSON response
4. GPT-5.2 returns: `{"status": "DANGER"/"SAFE", "reason": "...", "confidence": 0.0-1.0}`
5. If GPT says SAFE with â‰¥80% confidence â†’ suppress the alert (false positive override)
6. If DANGER â†’ generate TTS spoken warning â†’ play audio â†’ log to DB â†’ emit to dashboard
7. Timeout (>3s) â†’ falls back to local rule-based alert
8. Rate limited â†’ exponential backoff (30s base, 300s max) + local fallback

**2. `trigger_drowsy_alert(telemetry)` â€” Local Path (No GPT)**
Used for: Drowsy timer reaching 4+ seconds
Pipeline:
1. Immediately fires local rule-based alert (no API call)
2. Uses pre-written fallback messages from config
3. Generates TTS â†’ plays audio â†’ logs to DB â†’ emits to dashboard
4. **Guaranteed** to fire â€” no API dependency

#### Cooldown & Override
- Normal cooldown: 5 seconds between alerts
- Critical drowsy override (8s+): `force=True` bypasses cooldown (only checks if currently speaking)
- Rate limit backoff: exponential, 30s base â†’ 300s max

#### OpenAI Client Configuration
- Model: `gpt-5.2`
- `max_retries=0` â€” no SDK retries, system handles fallback manually
- `max_completion_tokens=100` â€” short responses for speed
- `temperature=0.3` â€” focused, deterministic output
- `timeout=3.0` seconds â€” enforced via `openai.APITimeoutError`
- TTS model: `tts-1`, voice: `onyx` (deep male), format: `mp3`
- Audio: pygame-ce mixer at 24kHz mono

### 5.6 `app/routes.py` â€” Flask Routes & Engine Controller

#### Routes
| Route | Method | Purpose |
|-------|--------|---------|
| `/` | GET | Serves the JARVIS dashboard HTML |
| `/video_feed` | GET | MJPEG video stream (30fps target) |
| `/api/stats` | GET | JSON incident statistics for current session |
| `/api/incidents` | GET | JSON list of recent 50 incidents |

#### Engine Controller
- `_start_engine()`: Initializes Camera, AICore, Jarvis, starts Thread A + Thread C
- `stop_engine()`: Gracefully shuts down all threads and resources
- SocketIO `connect` event: Sends system status to newly connected dashboard clients

#### Thread A â€” Processing Loop (Main Loop)
Runs continuously at camera speed (~30fps):
1. Read frame from camera
2. Run AI detection (`ai_core.process_frame()`) â€” YOLO every 10th frame
3. Encode frame as JPEG for MJPEG streaming
4. Emit telemetry via SocketIO (throttled to 10Hz)
5. Check alert conditions:
   - **Drowsy timer â‰¥ 4s** â†’ Local alert (PATH A) â€” no GPT
   - **Drowsy timer â‰¥ 8s** â†’ Local alert with force override (bypasses cooldown)
   - **EAR below threshold / danger frames / distraction** â†’ GPT-5.2 alert (PATH B)

#### Thread C â€” Spatial Analysis
Every 5 seconds:
1. Grab camera frame
2. Send to GPT-5.2 with spatial analysis prompt
3. GPT-5.2 returns 3-line tactical assessment:
   - SUBJECTS: (people and their state)
   - ENV: (environment, objects, lighting)
   - STATUS: (assessment) | THREAT: (LOW/MEDIUM/HIGH)
4. Result stored in ai_core for the HUD spatial panel

### 5.7 `app/database.py` â€” SQLAlchemy Models

#### Incident Table
| Column | Type | Description |
|--------|------|-------------|
| id | Integer | Auto-increment primary key |
| timestamp | DateTime | When the incident occurred |
| alert_type | String | DROWSINESS, YAWNING, DISTRACTION, HEAD_POSE, GENERAL |
| severity | String | WARNING or DANGER |
| ear_value | Float | Eye Aspect Ratio at time of incident |
| mar_value | Float | Mouth Aspect Ratio |
| yaw_angle | Float | Head yaw in degrees |
| pitch_angle | Float | Head pitch in degrees |
| detected_objects | String | Comma-separated list of objects |
| jarvis_response | Text | Full GPT-5.2 response or local fallback message |
| attention_score | Float | 0-100 composite score |
| blink_rate | Float | Blinks per minute |

#### Session Table
| Column | Type | Description |
|--------|------|-------------|
| id | Integer | Auto-increment |
| start_time | DateTime | Session start |
| end_time | DateTime | Session end |
| total_incidents | Integer | Count of incidents |
| max_severity | String | Worst severity reached |

Functions: `log_incident()`, `get_incident_stats()`, `get_recent_incidents()`

---

## 6. AI Detection Pipeline

```
Camera Frame (640Ã—480, 30fps)
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  MediaPipe Face Landmarker       â”‚
â”‚  478 landmarks â†’ EAR, MAR,      â”‚
â”‚  head pose (yaw/pitch),         â”‚
â”‚  blink detection, iris tracking  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                   â”‚
       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
       â–¼           â–¼           â–¼
  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚ Drowsy? â”‚ â”‚ Yawning?â”‚ â”‚ Looking     â”‚
  â”‚ EAR<0.25â”‚ â”‚ MAR>0.70â”‚ â”‚ Away?       â”‚
  â”‚ 15framesâ”‚ â”‚ 8 framesâ”‚ â”‚ Yaw>25Â°     â”‚
  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
       â”‚           â”‚              â”‚
       â–¼           â–¼              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  YOLOv8 Nano (every 10 frames)  â”‚
â”‚  â†’ phone, bottle, cup, knife    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                   â”‚
                   â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  MediaPipe Hands                 â”‚
â”‚  â†’ hand near face, phone at ear â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                   â”‚
                   â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Behavior Analysis               â”‚
â”‚  â†’ phone_near_ear, drinking,     â”‚
â”‚    looking_down, hand_on_head    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                   â”‚
                   â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Attention Score (0-100)         â”‚
â”‚  EAR(30%) + Blink(15%) +        â”‚
â”‚  MAR(15%) + Head(20%) +         â”‚
â”‚  Distraction(20%)               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                   â”‚
                   â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Safety Status                   â”‚
â”‚  SAFE / WARNING / DANGER         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## 7. Alert System â€” 2-Path Architecture

### PATH A: Drowsy Timer â†’ Instant Local Alert
```
Drowsy Timer hits 4 seconds
       â”‚
       â–¼
[JARVIS] ğŸ’¤ Drowsy timer triggered â€” instant local alert (no GPT)
       â”‚
       â–¼
Pre-written message: "Driver, your eyes are closing. Please pull over
and take a break immediately."
       â”‚
       â–¼
OpenAI TTS â†’ pygame audio â†’ Speaker
       â”‚
       â–¼
Log to SQLite + Emit to Dashboard
```
**Why local?** GPT-5.2 can fail (timeout, rate limit, misjudge). Drowsiness is life-critical, so the 4-second alert is **guaranteed** to fire with no API dependency.

At 8+ seconds: `force=True` bypasses the 5-second cooldown entirely.

### PATH B: Other Dangers â†’ GPT-5.2 Vision Analysis
```
EAR below threshold / Danger frames / Distraction detected
       â”‚
       â–¼
Encode frame â†’ base64 JPEG (quality 70)
       â”‚
       â–¼
Send to GPT-5.2 Vision with sensor context:
  "EAR=0.180, MAR=0.120, Yaw=5.2Â°, Pitch=-3.1Â°,
   Attention=45/100, BlinkRate=8/min"
       â”‚
       â–¼
GPT-5.2 responds (within 3s timeout):
  {"status": "DANGER", "reason": "Micro-sleep detected", "confidence": 0.93}
       â”‚
       â”œâ”€â”€ If SAFE + confidence â‰¥ 80% â†’ Suppress alert (false positive override)
       â”‚
       â”œâ”€â”€ If DANGER â†’ Generate TTS warning â†’ Play audio
       â”‚
       â”œâ”€â”€ If Timeout (>3s) â†’ Local fallback alert
       â”‚
       â””â”€â”€ If Rate Limited â†’ Exponential backoff + local fallback
```

### Offline Fallback Messages
| Alert Type | Message |
|-----------|---------|
| DROWSINESS | "Driver, your eyes are closing. Please pull over and take a break immediately." |
| YAWNING | "Frequent yawning detected. Consider stopping for rest at the next safe location." |
| DISTRACTION | "Put your phone down and focus on the road. Your life depends on it." |
| HEAD_POSE | "Eyes on the road, driver. You have been looking away for too long." |
| GENERAL | "Your attention level is critically low. Please stay focused on driving safely." |

---

## 8. Dashboard & Frontend

### Layout (4-Panel Grid)
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        â”‚     TELEMETRY        â”‚
â”‚     LIVE FEED          â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚     (MJPEG Stream)     â”‚  â”‚  ATTENTION   â”‚    â”‚
â”‚                        â”‚  â”‚   GAUGE      â”‚    â”‚
â”‚     Camera 01          â”‚  â”‚   (0-100)    â”‚    â”‚
â”‚     30fps              â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚                        â”‚  â”Œâ”€â”€â”¬â”€â”€â”¬â”€â”€â”¬â”€â”€â”      â”‚
â”‚                        â”‚  â”‚DRâ”‚YWâ”‚DIâ”‚HPâ”‚      â”‚
â”‚                        â”‚  â””â”€â”€â”´â”€â”€â”´â”€â”€â”´â”€â”€â”˜      â”‚
â”‚                        â”‚  EAR / MAR Chart    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚     J.A.R.V.I.S.       â”‚   SESSION STATS     â”‚
â”‚     Feed / Logs        â”‚   Total | Drowsy    â”‚
â”‚                        â”‚   Yawning | Distractâ”‚
â”‚                        â”‚   AI Latency        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Top Header Bar â€” 3-Tier Drowsiness Status
The top bar shows the current drowsiness state only:

| State | Display | Color |
|-------|---------|-------|
| No drowsiness detected | ğŸŸ¢ **SAFE** | Green |
| Drowsiness detected, timer < 4s | ğŸŸ  **WARNING** | Orange/Amber |
| Drowsiness â‰¥ 4s (alert firing) | ğŸ”´ **DANGER** | Red (+ red overlay flash) |

### Real-Time Elements
- **Attention Gauge**: SVG ring showing 0-100 score, color transitions (green â†’ orange â†’ red)
- **Status Cards**: 4 cards for Drowsiness, Yawning, Distraction, Head Pose â€” each with active/inactive indicators
- **Drowsiness Card**: Shows tier labels â€” âœ… SAFE / âš ï¸ WARNING 2.3s / ğŸ”´ DANGER 5.1s (client-side smooth 20Hz timer)
- **EAR/MAR Chart**: Chart.js line graph with 100-point rolling history, threshold lines drawn
- **JARVIS Feed**: Last 3 alert messages with timestamps
- **Session Stats**: Total alerts, drowsiness count, yawning count, distraction count
- **AI Latency**: Real-time processing time in milliseconds
- **Danger Overlay**: Full-screen red flash when in DANGER state
- **System Clock**: HH:MM:SS live clock
- **Session Uptime**: Running time since dashboard connected
- **FPS Counter**: Camera frames per second

### Design Theme
- **Iron Man / JARVIS** aesthetic
- Colors: Dark background (#08090d), Orange accents (#ff8c00), White text
- Fonts: Orbitron (headers), Rajdhani (body), Share Tech Mono (data)
- Neon glow effects, animated beacon, arc reactor logo element
- Scanline effect on video feed

---

## 9. Database & Logging

- **Engine**: SQLite via SQLAlchemy 2.0
- **File**: `adar_logs.db` (auto-created in project root)
- **Auto-migration**: Adds new columns to existing tables on startup
- **Thread-safe**: Uses `scoped_session` for safe multi-thread access
- Every alert (both GPT-5.2 and local fallback) is logged with full telemetry
- Dashboard fetches stats via `/api/stats` every 5 seconds

---

## 10. Configuration & Thresholds

### OpenAI API
```python
OPENAI_MODEL = "gpt-5.2"           # Frontier model (NOT gpt-5.2-instant â€” doesn't exist)
OPENAI_TTS_MODEL = "tts-1"          # Text-to-speech
OPENAI_TTS_VOICE = "onyx"           # Deep male voice
GPT_TIMEOUT = 3.0                   # 3 second hard timeout
```

### Detection Thresholds
```python
EAR_THRESHOLD = 0.25                # Eye Aspect Ratio â€” below = drowsy
EAR_CONSEC_FRAMES = 15              # Frames to confirm drowsiness
MAR_THRESHOLD = 0.70                # Mouth Aspect Ratio â€” above = yawning
MAR_CONSEC_FRAMES = 8               # Frames to confirm yawning
HEAD_YAW_THRESHOLD = 25             # Degrees â€” looking sideways
HEAD_PITCH_THRESHOLD = 20           # Degrees â€” looking up/down
BLINK_EAR_THRESHOLD = 0.18          # EAR threshold for blink detection
YOLO_CONFIDENCE = 0.45              # YOLO detection confidence
```

### Alert System
```python
JARVIS_COOLDOWN = 5                 # Seconds between alerts
DANGER_FRAME_THRESHOLD = 5          # Danger frames before GPT alert
DROWSY_ALERT_DURATION = 4.0         # Seconds of drowsiness before DANGER
JARVIS_BACKOFF_BASE = 30            # Rate limit backoff base (seconds)
JARVIS_BACKOFF_MAX = 300            # Max backoff (5 minutes)
```

### Camera
```python
CAMERA_WIDTH = 640
CAMERA_HEIGHT = 480
CAMERA_FPS = 30
CAMERA_JPEG_QUALITY = 80
CAMERA_FLIP_HORIZONTAL = True       # Mirror view
```

---

## 11. Threading Model

```
Main Thread (Flask/SocketIO Server)
    â”‚
    â”œâ”€â”€ Camera Thread (continuous)
    â”‚   â””â”€â”€ Captures frames at 30fps, atomic reference swap
    â”‚
    â”œâ”€â”€ Thread A â€” Processing Loop (continuous)
    â”‚   â””â”€â”€ Camera â†’ AI detection â†’ JPEG encode â†’ SocketIO emit â†’ Alert trigger
    â”‚       â”‚
    â”‚       â”œâ”€â”€ Spawns: Jarvis GPT-5.2 alert thread (on-demand, daemon)
    â”‚       â””â”€â”€ Spawns: Jarvis Local drowsy alert thread (on-demand, daemon)
    â”‚
    â””â”€â”€ Thread C â€” Spatial Scan (every 5 seconds)
        â””â”€â”€ Camera â†’ GPT-5.2 Vision â†’ Spatial analysis text â†’ Stored in AICore
```

### Concurrency Controls
- Camera: Lock-free atomic reference (no mutex)
- Frame for MJPEG: `threading.Lock` protects `_latest_frame_bytes`
- Jarvis: `threading.Lock` protects `is_speaking` flag
- Jarvis cooldown: `is_ready` property checks elapsed time + backoff
- Force override: Bypasses cooldown, only checks `is_speaking` and `_backoff_until`

---

## 12. Key Features Summary

### Core AI Detection
- âœ… **Drowsiness detection** â€” Multi-factor EAR analysis with 10-frame grace period
- âœ… **Yawning detection** â€” MAR threshold with consecutive frame confirmation
- âœ… **Head pose tracking** â€” Yaw + Pitch with hysteresis to prevent false positives
- âœ… **Object detection** â€” YOLOv8 Nano detects phone, bottle, cup, knife, etc.
- âœ… **Hand tracking** â€” MediaPipe Hands detects hand-to-face behaviors
- âœ… **Blink rate monitoring** â€” Rolling 60-second window
- âœ… **Attention score** â€” Weighted composite 0-100 with temporal smoothing
- âœ… **3-level safety status** â€” SAFE / WARNING / DANGER

### Alert System
- âœ… **GPT-5.2 Vision analysis** â€” Sends frame + sensor data, gets JSON response
- âœ… **GPT-5.2 false positive override** â€” SAFE with â‰¥80% confidence suppresses alert
- âœ… **Instant local drowsy alerts** â€” 4s+ drowsiness fires without API call
- âœ… **Critical drowsy override** â€” 8s+ bypasses cooldown entirely
- âœ… **OpenAI TTS spoken warnings** â€” Natural voice through speakers
- âœ… **Timeout fallback** â€” >3s GPT response â†’ local rule-based alert
- âœ… **Rate limit handling** â€” Exponential backoff + local fallback
- âœ… **Pre-written fallback messages** â€” Works even when API is down

### Dashboard
- âœ… **JARVIS/Iron Man themed** â€” Sci-fi command center aesthetic
- âœ… **Live MJPEG video feed** â€” 30fps camera stream
- âœ… **Real-time telemetry** â€” SocketIO at 10Hz
- âœ… **3-tier status bar** â€” SAFE â†’ WARNING â†’ DANGER based on drowsiness
- âœ… **Attention gauge** â€” SVG ring with color transitions
- âœ… **EAR/MAR chart** â€” Chart.js rolling timeline
- âœ… **Smooth drowsy timer** â€” Client-side 20Hz counter
- âœ… **Alert log** â€” Last 3 JARVIS messages
- âœ… **Session statistics** â€” Incident counts by type
- âœ… **Danger overlay** â€” Full-screen red flash

### Infrastructure
- âœ… **SQLite incident logging** â€” Every alert recorded with full telemetry
- âœ… **Lock-free camera** â€” Atomic reference swap, zero-latency
- âœ… **Multi-threaded architecture** â€” Camera, Processing, Spatial, Alert threads
- âœ… **Graceful shutdown** â€” Signal handler, resource cleanup
- âœ… **Auto DB migration** â€” New columns added safely to existing tables
- âœ… **Spatial environment scanning** â€” GPT-5.2 room analysis every 5s

---

## 13. How To Run

### Prerequisites
- Python 3.10+
- NVIDIA GPU with CUDA (for YOLOv8)
- Webcam connected
- OpenAI API key with GPT-5.2 and TTS access

### Setup
```bash
cd "E:\ADAR V3.0"
python -m venv .venv
.venv\Scripts\activate
pip install -r requirements.txt
```

### Set API Key
Create `.env` file or set environment variable:
```
OPENAI_API_KEY=sk-your-key-here
```

### Run
```bash
python main.py
```

### Access Dashboard
Open browser: **http://localhost:5000**

---

## Dependencies (requirements.txt)

```
flask>=3.1.0
flask-socketio>=5.5.1
eventlet>=0.37.0
opencv-python>=4.11.0
mediapipe>=0.10.30
ultralytics>=8.3.0
numpy>=1.26.4
openai>=1.61.0
pygame-ce>=2.5.3
sqlalchemy>=2.0.37
python-dotenv>=1.0.1
Pillow>=11.1.0
scipy>=1.15.0
```

---

*Document generated: February 12, 2026*
*ADAR V3.0 â€” Advanced Driver Attention & Response System*
*Built for the OpenAI Buildathon Grand Finale*
